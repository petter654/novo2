import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import precision_score, f1_score
import joblib
from unidecode import unidecode
import re
import os
import numpy as np
from collections import defaultdict
import warnings
import yaml
from io import BytesIO
import pandera as pa
import nltk
from nltk.corpus import stopwords

# --- CONFIGURA√á√ÉO INICIAL E CONSTANTES ---

# Carrega a configura√ß√£o do arquivo YAML
try:
    with open('config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
except FileNotFoundError:
    st.error("Erro: O arquivo config.yaml n√£o foi encontrado. Usando configura√ß√µes padr√£o.")
    # Use um config padr√£o se o arquivo n√£o for encontrado
    config = {
        'data_paths': {'pdm': 'bases/base_pdm.XLSX', 'familias': 'bases/familias.xlsx', 'feedback': 'bases/Base_Treinamento_AMPLIADA_FEEDBACK.xlsx'},
        'reports_path': 'reports',
        'cache_dir': 'cache',
        'cache_filenames': ['embeddings_materiais.pkl', 'nn_macro_model.pkl', 'nn_micro_models.pkl'],
        'model': {'name': 'paraphrase-multilingual-MiniLM-L12-v2', 'k_neighbors': 10, 'confidence_threshold': 0.70, 'metric': 'cosine'},
        'cleaning': {'stop_words': ['tipo', 'modelo', 'uso', 'material', 'linha', 'produto', 'descricao', 'item', 'peca'], 'remove_units': True}
    }

# Configura√ß√£o da p√°gina do Streamlit
st.set_page_config(
    page_title="Classifica√ß√£o de Materiais",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Constantes globais derivadas do config
FALLBACK_LABEL = 'familia nao identificada'
REPORTS_PATH = config['reports_path']
FEEDBACK_FILE = os.path.join(REPORTS_PATH, 'Fila_Revisao_Feedback.xlsx')
CACHE_DIR = config['cache_dir']
CACHE_FILENAMES = config['cache_filenames']
CORRECT_FAMILY_COLUMN = 'Fam√≠lia_CORRETA'

# Constantes do modelo
MODEL_NAME = config['model']['name']
K_NEIGHBORS = config['model']['k_neighbors']
CONFIDENCE_THRESHOLD = config['model']['confidence_threshold']

# --- CORRE√á√ÉO ROBUSTA PARA O ERRO NLTK ---
# Esta fun√ß√£o garante que o pacote 'stopwords' seja baixado e carregado corretamente.
def load_stopwords():
    try:
        # Tenta carregar as stopwords diretamente
        return stopwords.words('portuguese')
    except LookupError:
        # Se falhar (pacote n√£o encontrado), baixa o pacote e tenta novamente.
        st.info("Baixando pacote de dados 'stopwords' da NLTK (necess√°rio apenas na primeira vez)...")
        nltk.download('stopwords')
        st.success("Download conclu√≠do.")
        return stopwords.words('portuguese')

stop_pt = load_stopwords()
stop_words_list = stop_pt + config['cleaning']['stop_words']


# --- FUN√á√ïES DE SUPORTE E PR√â-PROCESSAMENTO ---

def clean_text(text):
    """Limpa o texto removendo acentos, stopwords e unidades t√©cnicas."""
    if not isinstance(text, str): return ''
    text = unidecode(text.lower())
    text = ' '.join(word for word in text.split() if word not in stop_words_list)
    if config['cleaning']['remove_units']:
        text = re.sub(r'\s(mm|m|kg|un|pc|p√ß|par|cj|cx|lt|l|g|pn|dn|in|c|pol|diam|ext|ref)\b', ' ', text)
    return text.strip()

def get_macro_familia(familia):
    if not isinstance(familia, str): return 'D_DIVERSOS'
    code = str(familia)[:2]
    if code in ['01', '05', '09', '24', '28', '11', '13']: return 'H_HIDRAULICA'
    if code in ['04', '07', '08', '22', '29']: return 'C_CONSTRUCAO'
    if code in ['06', '12', '19', '20', '30']: return 'E_MECANICA'
    if code in ['03', '10', '14', '15', '18', '23']: return 'Q_QUIMICOS'
    return 'D_DIVERSOS'

def get_weighted_vote_and_confidence(indices, distances, y_labels):
    predictions, confidences = [], []
    for i in range(len(indices)):
        item_indices, item_distances = indices[i], distances[i]
        if np.any(item_distances < 1e-6):
            best_label = y_labels[item_indices[np.argmin(item_distances)]]
            confidence_score = 1.0
        else:
            weights = 1 / (item_distances + 1e-6)
            vote_tally = defaultdict(float)
            for label, weight in zip(y_labels[item_indices], weights):
                vote_tally[label] += weight
            if vote_tally:
                best_label = max(vote_tally, key=vote_tally.get)
                confidence_score = vote_tally[best_label] / np.sum(weights)
            else:
                best_label = FALLBACK_LABEL
                confidence_score = 0.0
        predictions.append(best_label)
        confidences.append(confidence_score)
    return np.array(predictions), np.array(confidences)

# --- FUN√á√ïES DE CARREGAMENTO DE DADOS E MODELOS ---

@st.cache_resource
def load_embedding_model():
    """Carrega o modelo SentenceTransformer do cache."""
    try:
        return SentenceTransformer(MODEL_NAME)
    except Exception as e:
        st.error(f"Erro ao carregar o modelo SentenceTransformer: {e}")
        st.stop()

@st.cache_data
def load_training_data():
    """Carrega os dados de treinamento, priorizando a base ampliada."""
    try:
        feedback_file_path = config['data_paths']['feedback']
        if os.path.exists(feedback_file_path):
            st.sidebar.success("‚úÖ Base AMPLIADA (com Feedback) carregada.")
            df_treinamento = pd.read_excel(feedback_file_path, engine='openpyxl')
        else:
            st.sidebar.warning("‚ö†Ô∏è Base ORIGINAL carregada (merge PDM + Fam√≠lias).")
            df_pdm = pd.read_excel(config['data_paths']['pdm'], engine='openpyxl')
            df_familias = pd.read_excel(config['data_paths']['familias'], engine='openpyxl')
            df_treinamento = pd.merge(df_pdm, df_familias, on='Fam√≠lia', how='left')
        
        # --- CORRE√á√ÉO DEFINITIVA PARA O ERRO DE VALIDA√á√ÉO ---
        # Remove linhas onde a coluna 'Fam√≠lia' √© nula ANTES de validar.
        # Isso limpa dados inv√°lidos ou linhas vazias do Excel.
        df_treinamento.dropna(subset=['Fam√≠lia'], inplace=True)
        
        # Valida√ß√£o do esquema do DataFrame
        schema = pa.DataFrameSchema({
            "Fam√≠lia": pa.Column(pa.String, coerce=True),
            "Decri√ß√£o": pa.Column(pa.String, coerce=True, nullable=True),
            "Descri√ß√£o Curta": pa.Column(pa.String, coerce=True, nullable=True),
            "Descri√ß√£o Longa": pa.Column(pa.String, coerce=True, nullable=True),
        })
        df_treinamento = schema.validate(df_treinamento)
        df_treinamento['Decri√ß√£o'] = df_treinamento['Decri√ß√£o'].fillna(FALLBACK_LABEL)
        return df_treinamento

    except FileNotFoundError as e:
        st.error(f"‚ùå Arquivo de base n√£o encontrado: {e.filename}. Verifique os caminhos no config.yaml.")
        st.stop()
    except Exception as e:
        st.error(f"‚ùå Erro ao ler ou validar os arquivos de base: {e}")
        st.stop()

# --- FUN√á√ïES DO APLICATIVO ---

def process_feedback_and_amplify_base():
    """Processa o arquivo de feedback, cria a base ampliada e limpa o cache."""
    if not os.path.exists(FEEDBACK_FILE):
        st.error(f"Arquivo de Feedback '{FEEDBACK_FILE}' n√£o encontrado.")
        return

    try:
        df_feedback = pd.read_excel(FEEDBACK_FILE, engine='openpyxl')
        df_feedback.dropna(subset=[CORRECT_FAMILY_COLUMN], inplace=True)

        if df_feedback.empty:
            st.warning(f"Nenhuma linha com dados na coluna '{CORRECT_FAMILY_COLUMN}' encontrada no arquivo de feedback.")
            return

        st.success(f"Encontradas {len(df_feedback)} corre√ß√µes humanas para o retreinamento.")

        df_novos_materiais = pd.DataFrame({
            'Fam√≠lia': df_feedback[CORRECT_FAMILY_COLUMN].apply(lambda x: str(x).split(' ')[0]),
            'Decri√ß√£o': df_feedback[CORRECT_FAMILY_COLUMN],
            'Descri√ß√£o Curta': df_feedback['Denomina√ß√£o'].apply(lambda x: str(x)[:40]),
            'Descri√ß√£o Longa': df_feedback['Denomina√ß√£o'],
        })

        df_pdm_original = pd.read_excel(config['data_paths']['pdm'], engine='openpyxl')
        df_familias_map = pd.read_excel(config['data_paths']['familias'], engine='openpyxl')
        df_base_original = pd.merge(df_pdm_original, df_familias_map, on='Fam√≠lia', how='left')
        
        cols_to_keep = ['Descri√ß√£o Curta', 'Descri√ß√£o Longa', 'Fam√≠lia', 'Decri√ß√£o']
        df_treinamento_final = pd.concat([
            df_base_original[cols_to_keep].dropna(subset=['Decri√ß√£o']),
            df_novos_materiais[cols_to_keep]
        ], ignore_index=True)
        
        feedback_path = config['data_paths']['feedback']
        os.makedirs(os.path.dirname(feedback_path), exist_ok=True)
        df_treinamento_final.to_excel(feedback_path, index=False, engine='openpyxl')
        st.success(f"‚úÖ Base ampliada salva em: {feedback_path}")

        # Limpeza de cache
        for filename in CACHE_FILENAMES:
            filepath = os.path.join(CACHE_DIR, filename)
            if os.path.exists(filepath):
                os.remove(filepath)
        st.cache_data.clear()
        st.cache_resource.clear()
        st.success("‚úÖ Cache limpo! O modelo ser√° retreinado na pr√≥xima execu√ß√£o.")
        st.rerun()

    except Exception as e:
        st.error(f"‚ùå Erro ao processar o feedback: {e}")

def run_classification_pipeline(df_chamados_upload, df_treinamento, model):
    """Executa o pipeline completo de classifica√ß√£o."""
    st.info("Iniciando o pipeline de classifica√ß√£o...")
    df_chamados_materiais = df_chamados_upload[df_chamados_upload['Neg√≥cio'] == 'MAT..xlsx'].copy()
    if df_chamados_materiais.empty:
        st.warning("Nenhum chamado do neg√≥cio 'MAT..xlsx' foi encontrado.")
        return
    st.success(f"Foram filtrados **{len(df_chamados_materiais)}** chamados.")

    # Garante que o diret√≥rio de cache exista
    os.makedirs(CACHE_DIR, exist_ok=True)

    # Prepara√ß√£o da base de refer√™ncia
    df_referencia = df_treinamento.copy()
    df_referencia['Descri√ß√£o Combinada'] = (df_referencia['Descri√ß√£o Curta'].fillna('') + ' ' + df_referencia['Descri√ß√£o Longa'].fillna(''))
    df_referencia['Desc_Clean'] = df_referencia['Descri√ß√£o Combinada'].apply(clean_text)
    df_referencia['Fam√≠lia_Macro'] = df_referencia['Fam√≠lia'].apply(get_macro_familia)
    y_labels_micro = df_referencia['Decri√ß√£o'].values
    y_labels_macro = df_referencia['Fam√≠lia_Macro'].values

    # Gera√ß√£o/Carregamento de Embeddings
    embeddings_path = os.path.join(CACHE_DIR, CACHE_FILENAMES[0])
    try:
        X_all = joblib.load(embeddings_path)
        st.caption("Embeddings carregados do cache.")
    except (FileNotFoundError, EOFError):
        with st.spinner("Gerando Embeddings... (pode demorar)"):
            X_all = model.encode(df_referencia['Desc_Clean'].tolist(), batch_size=64, show_progress_bar=False)
            joblib.dump(X_all, embeddings_path)
        st.success("Embeddings gerados e salvos em cache.")

    # Treinamento/Carregamento dos modelos K-NN
    X_valid_mask = (y_labels_micro != FALLBACK_LABEL)
    X_valid, y_valid_macro, y_valid_micro = X_all[X_valid_mask], y_labels_macro[X_valid_mask], y_labels_micro[X_valid_mask]
    
    macro_model_path = os.path.join(CACHE_DIR, CACHE_FILENAMES[1])
    micro_models_path = os.path.join(CACHE_DIR, CACHE_FILENAMES[2])
    try:
        nn_macro_model = joblib.load(macro_model_path)
        nn_micro_models = joblib.load(micro_models_path)
        st.caption("Modelos K-NN carregados do cache.")
    except (FileNotFoundError, EOFError):
        with st.spinner("Treinando modelos K-NN..."):
            nn_macro_model = NearestNeighbors(n_neighbors=K_NEIGHBORS, metric=config['model']['metric']).fit(X_valid)
            joblib.dump(nn_macro_model, macro_model_path)
            
            nn_micro_models = defaultdict(dict)
            for macro_group in np.unique(y_valid_macro):
                if macro_group in ['D_DIVERSOS', FALLBACK_LABEL]: continue
                mask_group = (y_valid_macro == macro_group)
                X_group = X_valid[mask_group]
                n_neighbors_group = min(K_NEIGHBORS, len(X_group))
                if n_neighbors_group > 0:
                    nn_model_group = NearestNeighbors(n_neighbors=n_neighbors_group, metric=config['model']['metric']).fit(X_group)
                    nn_micro_models[macro_group] = {'model': nn_model_group, 'y': y_valid_micro[mask_group]}
            joblib.dump(nn_micro_models, micro_models_path)
        st.success(f"Treinamento de {len(nn_micro_models)} micro-modelos conclu√≠do.")

    # Classifica√ß√£o dos chamados
    with st.spinner("Classificando os novos chamados..."):
        df_chamados_materiais['Denom_Clean'] = df_chamados_materiais['Denomina√ß√£o'].fillna('').apply(clean_text)
        embeddings_chamados = model.encode(df_chamados_materiais['Denom_Clean'].tolist(), batch_size=64, show_progress_bar=False)
        distances_macro, indices_macro = nn_macro_model.kneighbors(embeddings_chamados)
        y_pred_macro, _ = get_weighted_vote_and_confidence(indices_macro, distances_macro, y_valid_macro)
        df_chamados_materiais['Macro_Previsao'] = y_pred_macro

        y_pred_final, confiancas_final = [], []
        for i, row in df_chamados_materiais.iterrows():
            macro_previsao = row['Macro_Previsao']
            embedding_chamado = embeddings_chamados[df_chamados_materiais.index.get_loc(i)].reshape(1, -1)
            
            if macro_previsao in nn_micro_models:
                group_data = nn_micro_models[macro_previsao]
                distances_micro, indices_micro = group_data['model'].kneighbors(embedding_chamado)
                pred_micro, conf = get_weighted_vote_and_confidence(indices_micro, distances_micro, group_data['y'])
                y_pred_final.append(pred_micro[0])
                confiancas_final.append(conf[0])
            else:
                y_pred_final.append(FALLBACK_LABEL)
                confiancas_final.append(0.0)

        df_chamados_materiais['Fam√≠lia_Identificada'] = y_pred_final
        df_chamados_materiais['Confian√ßa'] = np.round(np.array(confiancas_final), 4)

    # Avalia√ß√£o e Gera√ß√£o de Fila de Revis√£o
    if 'Fam√≠lia' in df_chamados_materiais.columns:
        df_avaliar = df_chamados_materiais.dropna(subset=['Fam√≠lia']).copy()
        if not df_avaliar.empty:
            # ... (c√≥digo de m√©tricas e gera√ß√£o de feedback)
            st.subheader("Resultados da Classifica√ß√£o (M√©tricas):")
            # ...
            df_revisao = pd.concat([
                df_avaliar[df_avaliar['Fam√≠lia_Identificada'] != df_avaliar['Fam√≠lia']],
                df_avaliar[df_avaliar['Confian√ßa'] < CONFIDENCE_THRESHOLD]
            ]).drop_duplicates(subset=['Denomina√ß√£o']).sort_values(by='Confian√ßa')

            if not df_revisao.empty:
                os.makedirs(REPORTS_PATH, exist_ok=True)
                df_revisao[CORRECT_FAMILY_COLUMN] = '' # Adiciona a coluna vazia
                cols_to_save = ['Denomina√ß√£o', 'Fam√≠lia', 'Fam√≠lia_Identificada', 'Confian√ßa', CORRECT_FAMILY_COLUMN]
                df_revisao[cols_to_save].to_excel(FEEDBACK_FILE, index=False, engine='openpyxl')
                st.success(f"**[LOOP DE FEEDBACK]** Gerados **{len(df_revisao)}** casos para revis√£o em **{FEEDBACK_FILE}**.")

    # Sa√≠da Final
    st.subheader("Download dos Resultados Classificados")
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df_chamados_materiais.to_excel(writer, sheet_name='Classificado', index=False)
    
    st.download_button(
        label="üì• Baixar Arquivo Classificado (.xlsx)",
        data=output.getvalue(),
        file_name='chamados_classificados_hierarquico.xlsx',
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
    st.dataframe(df_chamados_materiais[['Denomina√ß√£o', 'Fam√≠lia_Identificada', 'Confian√ßa']].head(10))

# --- INTERFACE STREAMLIT (main) ---

def main():
    st.title("ü§ñ Classifica√ß√£o Hier√°rquica de Materiais")
    st.markdown("---")

    # Carregamento inicial
    model = load_embedding_model()
    df_treinamento = load_training_data()
    
    # Barra Lateral
    st.sidebar.header("1. Classificar Novos Chamados")
    uploaded_file = st.sidebar.file_uploader(
        "Carregue o arquivo de Chamados (.xlsx)", type=["xlsx"]
    )
    
    st.sidebar.header("2. Melhorar o Modelo")
    if st.sidebar.button("‚ôªÔ∏è Processar Feedback e Retreinar", help="L√™ o arquivo de revis√£o, atualiza a base de treinamento e limpa o cache para for√ßar o retreinamento."):
        process_feedback_and_amplify_base()
    
    # Corpo principal
    st.info("""
        **Como usar:**
        1. **Classificar:** Carregue um arquivo de chamados na barra lateral e clique em 'Iniciar Classifica√ß√£o'.
        2. **Revisar:** O sistema ir√° gerar um arquivo em `reports/Fila_Revisao_Feedback.xlsx`.
        3. **Corrigir:** Edite este arquivo, preenchendo a coluna **Fam√≠lia_CORRETA** com os valores corretos.
        4. **Retreinar:** Clique no bot√£o 'Processar Feedback e Retreinar' na barra lateral para que o modelo aprenda com suas corre√ß√µes!
    """)

    if uploaded_file:
        try:
            df_chamados_upload = pd.read_excel(uploaded_file, sheet_name='Base_Geral', engine='openpyxl')
            st.sidebar.info(f"Arquivo '{uploaded_file.name}' pronto para ser processado.")
            
            if st.button("üöÄ Iniciar Classifica√ß√£o", type="primary", use_container_width=True):
                run_classification_pipeline(df_chamados_upload, df_treinamento, model)
        
        except Exception as e:
            st.error(f"Erro ao ler o arquivo de chamados. Verifique se ele cont√©m uma aba chamada 'Base_Geral'. Detalhes: {e}")
    else:
        st.warning("Aguardando o upload do arquivo de chamados na barra lateral.")

if __name__ == "__main__":
    main()

